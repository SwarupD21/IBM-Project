{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SwarupD21/IBM-Project/blob/main/UCE_Core_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd84811c",
        "outputId": "3421bfad-4ed4-41ae-e689-27cad7162c19"
      },
      "source": [
        "# Install the opendatasets library to download datasets from Kaggle\n",
        "%pip install opendatasets\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.11/dist-packages (0.1.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (from opendatasets) (1.7.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from opendatasets) (8.2.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2025.7.14)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kut1xL7LSwvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "800e79bd",
        "outputId": "90f0011f-17e6-4f1e-9955-5d806fa990a5"
      },
      "source": [
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/datasets/everydaycodings/multi-platform-online-courses-dataset\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping, found downloaded files in \"./multi-platform-online-courses-dataset\" (use force=True to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OuUsGjVFUVf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0df04c3b",
        "outputId": "c1005a00-a133-4860-b8b1-2ac1c5c57060"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# IMPORTANT: Replace 'path/to/your/dataset.csv' with the actual path to your downloaded dataset file\n",
        "dataset_path = './multi-platform-online-courses-dataset/Coursera.csv'\n",
        "\n",
        "# Check if the file exists before trying to read it\n",
        "if os.path.exists(dataset_path):\n",
        "    df = pd.read_csv(dataset_path)\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "    print(df.head())\n",
        "else:\n",
        "    print(f\"Error: Dataset not found at {dataset_path}\")\n",
        "    print(\"Please check the dataset path and filename.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully.\n",
            "  partner                                 course  \\\n",
            "0  Google                   Google Cybersecurity   \n",
            "1  Google                  Google Data Analytics   \n",
            "2  Google             Google Project Management:   \n",
            "3  Google  Google Digital Marketing & E-commerce   \n",
            "4  Google                      Google IT Support   \n",
            "\n",
            "                                              skills  rating reviewcount  \\\n",
            "0  {\" Network Security\",\" Python Programming\",\" L...     4.8       16.4k   \n",
            "1  {\" Data Analysis\",\" R Programming\",\" SQL\",\" Bu...     4.8      133.4k   \n",
            "2  {\" Project Management\",\" Strategy and Operatio...     4.8       97.3k   \n",
            "3  {\" Digital Marketing\",\" Marketing\",\" Marketing...     4.8       21.4k   \n",
            "4  {\" Computer Networking\",\" Network Architecture...     4.8      181.4k   \n",
            "\n",
            "       level             certificatetype       duration  crediteligibility  \n",
            "0  Beginner    Professional Certificate    3 - 6 Months              False  \n",
            "1  Beginner    Professional Certificate    3 - 6 Months               True  \n",
            "2  Beginner    Professional Certificate    3 - 6 Months               True  \n",
            "3  Beginner    Professional Certificate    3 - 6 Months              False  \n",
            "4  Beginner    Professional Certificate    3 - 6 Months               True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wZiwiNvJZONN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "27994cd8",
        "outputId": "6a883981-9115-487d-b81d-ca4ee9c13763"
      },
      "source": [
        "# Check if the 'skills' column exists in the DataFrame\n",
        "if 'skills' in df.columns:\n",
        "    print(\"First 10 entries in the 'skills' column:\")\n",
        "    display(df['skills'].head(10))\n",
        "\n",
        "    print(\"\\nData type of the 'skills' column:\")\n",
        "    print(df['skills'].dtype)\n",
        "\n",
        "    # Check for missing values in the 'skills' column\n",
        "    print(\"\\nMissing values in the 'skills' column:\")\n",
        "    print(df['skills'].isnull().sum())\n",
        "\n",
        "else:\n",
        "    print(\"The 'skills' column was not found in the DataFrame.\")\n",
        "    print(\"Please check the column names in your dataset.\")\n",
        "    print(\"Available columns:\", df.columns.tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 entries in the 'skills' column:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    {\" Network Security\",\" Python Programming\",\" L...\n",
              "1    {\" Data Analysis\",\" R Programming\",\" SQL\",\" Bu...\n",
              "2    {\" Project Management\",\" Strategy and Operatio...\n",
              "3    {\" Digital Marketing\",\" Marketing\",\" Marketing...\n",
              "4    {\" Computer Networking\",\" Network Architecture...\n",
              "5    {\" Python Programming\",\" Data Science\",\" Machi...\n",
              "6    {\" User Experience\",\" User Experience Design\",...\n",
              "7    {\" Python Programming\",\" Data Visualization\",\"...\n",
              "8    {\" Machine Learning\",\" Machine Learning Algori...\n",
              "9    {\" Data Science\",\" Python Programming\",\" Data ...\n",
              "Name: skills, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>skills</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{\" Network Security\",\" Python Programming\",\" L...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{\" Data Analysis\",\" R Programming\",\" SQL\",\" Bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{\" Project Management\",\" Strategy and Operatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{\" Digital Marketing\",\" Marketing\",\" Marketing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{\" Computer Networking\",\" Network Architecture...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>{\" Python Programming\",\" Data Science\",\" Machi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>{\" User Experience\",\" User Experience Design\",...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>{\" Python Programming\",\" Data Visualization\",\"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>{\" Machine Learning\",\" Machine Learning Algori...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>{\" Data Science\",\" Python Programming\",\" Data ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data type of the 'skills' column:\n",
            "object\n",
            "\n",
            "Missing values in the 'skills' column:\n",
            "51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "a6919cd4",
        "outputId": "6836a0f1-6c92-442f-da9a-823859b25ebb"
      },
      "source": [
        "import json\n",
        "\n",
        "# Function to parse the skills string into a list of strings\n",
        "def parse_skills(skills_string):\n",
        "    if pd.isna(skills_string):\n",
        "        return []  # Return an empty list for missing values\n",
        "    try:\n",
        "        # The string looks like a JSON array, so we can try parsing it\n",
        "        # Need to replace single quotes with double quotes for valid JSON\n",
        "        skills_string = skills_string.replace(\"'\", '\"')\n",
        "        # The string also has leading/trailing curly braces which are not part of JSON array\n",
        "        skills_string = skills_string.strip('{}')\n",
        "        # Wrap in brackets to form a valid JSON array string\n",
        "        json_string = f'[{skills_string}]'\n",
        "        # Load the JSON string\n",
        "        skills_list = json.loads(json_string)\n",
        "        # Clean up each skill string (remove extra quotes and whitespace)\n",
        "        cleaned_skills = [skill.strip().strip('\"') for skill in skills_list]\n",
        "        return cleaned_skills\n",
        "    except json.JSONDecodeError:\n",
        "        # If JSON decoding fails, return an empty list or handle as appropriate\n",
        "        print(f\"Warning: Could not parse skills string: {skills_string}\")\n",
        "        return [] # Return empty list for parsing errors\n",
        "\n",
        "# Apply the parsing function to the 'skills' column\n",
        "if 'skills' in df.columns:\n",
        "    df['parsed_skills'] = df['skills'].apply(parse_skills)\n",
        "    print(\"\\n'skills' column parsed and stored in 'parsed_skills' column.\")\n",
        "    print(\"First 10 entries in the 'parsed_skills' column:\")\n",
        "    display(df['parsed_skills'].head(10))\n",
        "else:\n",
        "    print(\"The 'skills' column was not found in the DataFrame.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Could not parse skills string: Course\n",
            "Warning: Could not parse skills string: Specialization\n",
            "Warning: Could not parse skills string: Course\n",
            "Warning: Could not parse skills string: Degree\n",
            "\n",
            "'skills' column parsed and stored in 'parsed_skills' column.\n",
            "First 10 entries in the 'parsed_skills' column:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    [Network Security, Python Programming, Linux, ...\n",
              "1    [Data Analysis, R Programming, SQL, Business C...\n",
              "2    [Project Management, Strategy and Operations, ...\n",
              "3    [Digital Marketing, Marketing, Marketing Manag...\n",
              "4    [Computer Networking, Network Architecture, Ne...\n",
              "5    [Python Programming, Data Science, Machine Lea...\n",
              "6    [User Experience, User Experience Design, User...\n",
              "7    [Python Programming, Data Visualization, Micro...\n",
              "8    [Machine Learning, Machine Learning Algorithms...\n",
              "9    [Data Science, Python Programming, Data Analys...\n",
              "Name: parsed_skills, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>parsed_skills</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Network Security, Python Programming, Linux, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Data Analysis, R Programming, SQL, Business C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Project Management, Strategy and Operations, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Digital Marketing, Marketing, Marketing Manag...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Computer Networking, Network Architecture, Ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[Python Programming, Data Science, Machine Lea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[User Experience, User Experience Design, User...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[Python Programming, Data Visualization, Micro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[Machine Learning, Machine Learning Algorithms...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[Data Science, Python Programming, Data Analys...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "id": "a5644d2d",
        "outputId": "5bc457ab-320d-411c-e346-f37ae516ddfd"
      },
      "source": [
        "# Flatten the list of lists in the 'parsed_skills' column\n",
        "all_skills = [skill for skills_list in df['parsed_skills'] for skill in skills_list]\n",
        "\n",
        "# Get the unique skills\n",
        "unique_skills = set(all_skills)\n",
        "\n",
        "print(f\"Total number of skills extracted: {len(all_skills)}\")\n",
        "print(f\"Total number of unique skills: {len(unique_skills)}\")\n",
        "\n",
        "# Display the first 20 unique skills as an example\n",
        "print(\"\\nFirst 20 unique skills:\")\n",
        "display(list(unique_skills)[:20])\n",
        "\n",
        "# Optionally, count the frequency of each skill\n",
        "from collections import Counter\n",
        "skill_counts = Counter(all_skills)\n",
        "\n",
        "print(\"\\nTop 20 most frequent skills:\")\n",
        "display(skill_counts.most_common(20))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of skills extracted: 12760\n",
            "Total number of unique skills: 429\n",
            "\n",
            "First 20 unique skills:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['Collaboration',\n",
              " '',\n",
              " 'Business Research',\n",
              " '(30.2k reviews)',\n",
              " 'Full-Stack Web Development',\n",
              " 'Big Data',\n",
              " 'Dimensionality Reduction',\n",
              " 'Software Engineering',\n",
              " 'Cost Accounting',\n",
              " 'Computer Programming',\n",
              " 'Cash Management',\n",
              " 'Network Security',\n",
              " 'Business Design',\n",
              " 'Knitr',\n",
              " 'Cloud Clients',\n",
              " 'Storytelling',\n",
              " 'Internet Of Things',\n",
              " 'Machine Learning',\n",
              " 'People Development',\n",
              " 'Marketing Design']"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 20 most frequent skills:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('Leadership and Management', 357),\n",
              " ('Data Analysis', 263),\n",
              " ('Computer Programming', 215),\n",
              " ('Strategy', 214),\n",
              " ('Communication', 211),\n",
              " ('Critical Thinking', 193),\n",
              " ('Problem Solving', 184),\n",
              " ('Strategy and Operations', 184),\n",
              " ('Python Programming', 170),\n",
              " ('Machine Learning', 153),\n",
              " ('Business Analysis', 151),\n",
              " ('Planning', 140),\n",
              " ('Algorithms', 138),\n",
              " ('Finance', 134),\n",
              " ('Decision Making', 134),\n",
              " ('Data Management', 132),\n",
              " ('Marketing', 131),\n",
              " ('Probability & Statistics', 113),\n",
              " ('Cloud Computing', 112),\n",
              " ('General Statistics', 104)]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "id": "350abf3d",
        "outputId": "cfec64ac-d3de-44ab-e8c3-df429b5217f8"
      },
      "source": [
        "# Filter out irrelevant entries from the skill list\n",
        "# We'll remove empty strings and entries that look like review counts (contain '(' and ')')\n",
        "cleaned_skills_list = [skill for skill in all_skills if skill and not ('(' in skill and ')' in skill)]\n",
        "\n",
        "# Get the unique cleaned skills\n",
        "unique_cleaned_skills = set(cleaned_skills_list)\n",
        "\n",
        "print(f\"Total number of cleaned skills extracted: {len(cleaned_skills_list)}\")\n",
        "print(f\"Total number of unique cleaned skills: {len(unique_cleaned_skills)}\")\n",
        "\n",
        "# Display the first 20 unique cleaned skills as an example\n",
        "print(\"\\nFirst 20 unique cleaned skills:\")\n",
        "display(list(unique_cleaned_skills)[:20])\n",
        "\n",
        "# Optionally, count the frequency of each cleaned skill\n",
        "cleaned_skill_counts = Counter(cleaned_skills_list)\n",
        "\n",
        "print(\"\\nTop 20 most frequent cleaned skills:\")\n",
        "display(cleaned_skill_counts.most_common(20))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of cleaned skills extracted: 12441\n",
            "Total number of unique cleaned skills: 328\n",
            "\n",
            "First 20 unique cleaned skills:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['Collaboration',\n",
              " 'Business Research',\n",
              " 'Full-Stack Web Development',\n",
              " 'Big Data',\n",
              " 'Dimensionality Reduction',\n",
              " 'Software Engineering',\n",
              " 'Cost Accounting',\n",
              " 'Computer Programming',\n",
              " 'Cash Management',\n",
              " 'Network Security',\n",
              " 'Business Design',\n",
              " 'Knitr',\n",
              " 'Cloud Clients',\n",
              " 'Storytelling',\n",
              " 'Internet Of Things',\n",
              " 'Machine Learning',\n",
              " 'People Development',\n",
              " 'Marketing Design',\n",
              " 'DevOps',\n",
              " 'Calculus']"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 20 most frequent cleaned skills:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('Leadership and Management', 357),\n",
              " ('Data Analysis', 263),\n",
              " ('Computer Programming', 215),\n",
              " ('Strategy', 214),\n",
              " ('Communication', 211),\n",
              " ('Critical Thinking', 193),\n",
              " ('Problem Solving', 184),\n",
              " ('Strategy and Operations', 184),\n",
              " ('Python Programming', 170),\n",
              " ('Machine Learning', 153),\n",
              " ('Business Analysis', 151),\n",
              " ('Planning', 140),\n",
              " ('Algorithms', 138),\n",
              " ('Finance', 134),\n",
              " ('Decision Making', 134),\n",
              " ('Data Management', 132),\n",
              " ('Marketing', 131),\n",
              " ('Probability & Statistics', 113),\n",
              " ('Cloud Computing', 112),\n",
              " ('General Statistics', 104)]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "714cc366",
        "outputId": "77ae5746-a46a-4ad4-9ea7-75880e1c0887"
      },
      "source": [
        "# This cell defines the Personalized Recommendation Engine Node for the LangGraph.\n",
        "# It takes the identified skill gaps from the graph state and uses an LLM to suggest learning paths.\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "# Note: The LLM configuration is now handled within the recommend_learning_paths_node function\n",
        "# when the LangGraph is invoked.\n",
        "\n",
        "# print(\"\\nGenerating personalized learning path recommendations...\") # Removed direct execution print\n",
        "\n",
        "# Prepare the prompt for the LLM (This part is still useful for understanding the node's logic)\n",
        "# The prompt should ask the LLM to suggest learning resources for the identified skill gaps.\n",
        "# We'll focus on the first few skill gaps for brevity in the prompt.\n",
        "# skills_to_learn = list(skill_gaps)[:10] # This variable is defined within the node's scope during graph execution\n",
        "\n",
        "# if skills_to_learn: # Removed direct execution condition\n",
        "#     prompt = f\"Based on the following skill gaps: {', '.join(skills_to_learn)}. Please suggest personalized learning pathways, including types of resources (e.g., online courses, certifications, books, tutorials) to acquire these skills.\"\n",
        "\n",
        "#     print(\"\\nPrompt for the LLM:\") # Removed direct execution print\n",
        "#     print(prompt)\n",
        "\n",
        "    # In a real implementation, you would call the LLM here:\n",
        "    # This logic is now integrated into the recommend_learning_paths_node function in cell f09cee9e\n",
        "    # if gemini_model: # Removed direct execution condition\n",
        "    #     try:\n",
        "    #         response = gemini_model.generate_content(prompt)\n",
        "    #         print(\"\\nPersonalized Learning Path Recommendations:\") # Removed direct execution print\n",
        "    #         print(response.text)\n",
        "    #     except Exception as e:\n",
        "    #         print(f\"Error calling LLM: {e}\") # Removed direct execution print\n",
        "    #         print(\"An error occurred while generating recommendations.\") # Removed direct execution print\n",
        "    # else: # Removed direct execution else\n",
        "    #     print(\"\\nLLM is not configured. Cannot generate recommendations.\") # Removed direct execution print\n",
        "\n",
        "\n",
        "# else: # Removed direct execution else\n",
        "#     print(\"\\nNo skill gaps identified. No recommendations needed.\") # Removed direct execution print\n",
        "\n",
        "print(\"Cell defines the recommend_learning_paths_node function for LangGraph.\")\n",
        "print(\"Run the cell that invokes the compiled graph (e.g., cell b992dd94) to execute this node.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cell defines the recommend_learning_paths_node function for LangGraph.\n",
            "Run the cell that invokes the compiled graph (e.g., cell b992dd94) to execute this node.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f09cee9e",
        "outputId": "56370e49-a89e-446b-eaf7-aff2568f1d7f"
      },
      "source": [
        "# Install necessary libraries\n",
        "%pip install --quiet -U langchain_google_genai langgraph langchainhub\n",
        "# Install scikit-learn for cosine similarity\n",
        "%pip install --quiet scikit-learn\n",
        "\n",
        "# Import necessary classes\n",
        "from typing import TypedDict, Annotated, List\n",
        "from langgraph.graph import StateGraph, END\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import os\n",
        "import json\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer # Import SentenceTransformer\n",
        "\n",
        "\n",
        "# --- LangGraph State Definition ---\n",
        "# This defines the structure of the state that will be passed between nodes in the graph.\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph.\n",
        "\n",
        "    Attributes:\n",
        "        dataset_path: The path to the dataset.\n",
        "        dataframe: The pandas DataFrame containing the dataset.\n",
        "        skills_data: A list of extracted skills from the dataset.\n",
        "        unique_job_market_skills: set # Set of unique skills from the job market.\n",
        "        individual_skills: List[str] # Individual skills provided by the user.\n",
        "        skill_gaps: set # Skill gaps identified (using embeddings).\n",
        "        recommendations: str # Recommendations generated by LLM.\n",
        "        error: str # Error message if any.\n",
        "        stored_result: str # Attribute to represent the stored result.\n",
        "        # Simplified state, removing mapping-related attributes\n",
        "        # job_market_categories: set\n",
        "        # individual_categories: set\n",
        "        # category_gaps: set\n",
        "        # detailed_skill_gaps: dict\n",
        "    \"\"\"\n",
        "    dataset_path: str\n",
        "    dataframe: pd.DataFrame\n",
        "    skills_data: List[str]\n",
        "    unique_job_market_skills: set\n",
        "    individual_skills: List[str]\n",
        "    skill_gaps: set\n",
        "    recommendations: str\n",
        "    error: str\n",
        "    stored_result: str\n",
        "    # job_market_categories: set # Removed\n",
        "    # individual_categories: set # Removed\n",
        "    # category_gaps: set # Removed\n",
        "    # detailed_skill_gaps: dict # Removed\n",
        "    # job_market_embeddings_dict: dict # Added for clarity, though passed directly\n",
        "    # individual_embeddings_dict: dict # Added for clarity, though passed directly\n",
        "\n",
        "\n",
        "# --- Node Definitions ---\n",
        "# These functions represent the individual steps or nodes in the LangGraph workflow.\n",
        "\n",
        "def load_data_node(state: GraphState):\n",
        "    \"\"\"\n",
        "    LangGraph Node: Loads the dataset from the specified path into a DataFrame.\n",
        "    This node is the starting point for the data processing graph.\n",
        "    \"\"\"\n",
        "    print(\"---LOADING DATA (Graph 1)---\")\n",
        "    dataset_path = state.get('dataset_path')\n",
        "\n",
        "    if not dataset_path:\n",
        "        return {\"error\": \"Dataset path not provided in state.\"}\n",
        "\n",
        "    if os.path.exists(dataset_path):\n",
        "        try:\n",
        "            df = pd.read_csv(dataset_path)\n",
        "            print(\"Dataset loaded successfully.\")\n",
        "            return {\"dataframe\": df, \"error\": \"\"}\n",
        "        except Exception as e:\n",
        "            return {\"error\": f\"Error loading dataset: {e}\"}\n",
        "    else:\n",
        "        return {\"error\": f\"Error: Dataset not found at {dataset_path}\"}\n",
        "\n",
        "\n",
        "def wrangle_data_node(state: GraphState):\n",
        "    \"\"\"\n",
        "    LangGraph Node: Processes the 'skills' column of the DataFrame.\n",
        "    It parses the skill strings and extracts unique skills.\n",
        "    \"\"\"\n",
        "    print(\"---WRANGLING DATA (Graph 1)---\")\n",
        "    df = state.get('dataframe')\n",
        "\n",
        "    if df is None:\n",
        "        return {\"error\": \"DataFrame not found in state. Cannot wrangle data.\"}\n",
        "\n",
        "    if 'skills' in df.columns:\n",
        "        def parse_skills(skills_string):\n",
        "            if pd.isna(skills_string):\n",
        "                return []\n",
        "            try:\n",
        "                skills_string = skills_string.replace(\"'\", '\"')\n",
        "                skills_string = skills_string.strip('{}')\n",
        "                json_string = f'[{skills_string}]'\n",
        "                skills_list = json.loads(json_string)\n",
        "                cleaned_skills = [skill.strip().strip('\"') for skill in skills_list]\n",
        "                return cleaned_skills\n",
        "            except json.JSONDecodeError:\n",
        "                return []\n",
        "\n",
        "        df['parsed_skills'] = df['skills'].apply(parse_skills)\n",
        "        all_skills = [skill for skills_list in df['parsed_skills'] for skill in skills_list]\n",
        "        cleaned_skills_list = [skill for skill in all_skills if skill and not ('(' in skill and ')' in skill)]\n",
        "        unique_cleaned_skills = set(cleaned_skills_list)\n",
        "\n",
        "        print(f\"Total unique cleaned skills extracted: {len(unique_cleaned_skills)}\")\n",
        "\n",
        "        return {\"skills_data\": cleaned_skills_list, \"unique_job_market_skills\": unique_cleaned_skills, \"error\": \"\"}\n",
        "\n",
        "    else:\n",
        "        return {\"error\": \"The 'skills' column was not found in the DataFrame. Cannot wrangle skills.\"}\n",
        "\n",
        "\n",
        "# --- Auxiliary Functions (Called Outside the Compiled Graph) ---\n",
        "# These functions perform specific tasks but are invoked separately in the orchestration cell,\n",
        "# not as part of the compiled `app_data_processing` graph's flow.\n",
        "\n",
        "# Preliminary mapping kept only for potential use in LLM prompt generation, not for coverage check.\n",
        "preliminary_skill_mapping = {\n",
        "    \"Data Analysis\": [\"Data Analysis\", \"Business Analysis\", \"Data Management\", \"Spreadsheet Software\", \"Business Intelligence\", \"Data Visualization\"],\n",
        "    \"Programming\": [\"Computer Programming\", \"Python Programming\", \"R Programming\", \"SQL\", \"Algorithms\", \"C++ Programming\", \"Java Programming\", \"Web Development\", \"Full-Stack Web Development\", \"Front-End Web Development\", \"Back-End Web Development\"],\n",
        "    \"Machine Learning & AI\": [\"Machine Learning\", \"Applied Machine Learning\", \"Deep Learning\", \"Artificial Neural Networks\", \"Statistical Machine Learning\", \"Natural Language Processing\", \"Computer Vision\", \"Dimensionality Reduction\"],\n",
        "    \"Business Strategy\": [\"Strategy\", \"Strategy and Operations\", \"Planning\", \"Business Research\", \"Decision Making\", \"Negotiation\", \"Innovation\"],\n",
        "    \"Management & Leadership\": [\"Leadership and Management\", \"Change Management\", \"People Development\", \"Human Resources\", \"Organizational Development\"],\n",
        "    \"Communication & Soft Skills\": [\"Communication\", \"Critical Thinking\", \"Problem Solving\", \"Collaboration\", \"Storytelling\", \"Writing\"],\n",
        "    \"Finance & Accounting\": [\"Finance\", \"Accounting\", \"Financial Accounting\", \"Cost Accounting\", \"Investment Management\", \"Risk Management\", \"Cash Management\"],\n",
        "    \"Marketing\": [\"Marketing\", \"Digital Marketing\", \"Marketing Management\", \"Branding\"],\n",
        "    \"Cloud & IT\": [\"Cloud Computing\", \"DevOps\", \"Computer Networking\", \"Network Security\", \"Cloud Clients\", \"Internet Of Things\", \"Software As A Service\", \"Linux\", \"Databases\", \"Cybersecurity\"],\n",
        "    \"Project Management\": [\"Project Management\", \"Agile Software Development\", \"Scrum (Software Development)\"],\n",
        "    \"Design\": [\"User Experience Design\", \"User Experience\", \"User Interface\", \"Graphic Design\", \"Marketing Design\", \"Business Design\"],\n",
        "    \"Statistics & Probability\": [\"Probability & Statistics\", \"General Statistics\"],\n",
        "    \"Mathematics\": [\"Calculus\", \"Linear Algebra\"]\n",
        "}\n",
        "\n",
        "# Set a similarity threshold for embeddings\n",
        "EMBEDDING_SIMILARITY_THRESHOLD = 0.7 # Cosine similarity score above this indicates a match\n",
        "\n",
        "\n",
        "def identify_skill_gaps(unique_job_market_skills: set, individual_skills: List[str], job_market_embeddings_dict: dict, individual_embeddings_dict: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Auxiliary Function: Identifies skills present in the job market data\n",
        "    but not in the individual's provided list of skills, using embedding similarity\n",
        "    and direct match only for coverage check. Returns a dictionary with skill gaps.\n",
        "    \"\"\"\n",
        "    print(\"---IDENTIFYING SKILL GAPS (Using Embeddings Only for Coverage)---\")\n",
        "    if unique_job_market_skills is None:\n",
        "        print(\"Warning: Job market skills not provided.\")\n",
        "        return {\"skill_gaps\": set()}\n",
        "\n",
        "    if individual_skills is None:\n",
        "         print(\"Warning: Individual skills not provided.\")\n",
        "         return {\"skill_gaps\": unique_job_market_skills.copy()}\n",
        "\n",
        "    if not job_market_embeddings_dict or not individual_embeddings_dict:\n",
        "         print(\"Warning: Embedding dictionaries not provided or empty. Cannot use embedding similarity.\")\n",
        "         # Fallback to direct string match only if embeddings are not available\n",
        "         individual_skills_set = set([skill.lower() for skill in individual_skills])\n",
        "         job_market_skills_set = set([skill.lower() for skill in unique_job_market_skills])\n",
        "         skill_gaps = job_market_skills_set - individual_skills_set\n",
        "         print(\"Falling back to direct string match only.\")\n",
        "         print(f\"\\nIdentified {len(skill_gaps)} Specific Skill Gaps (direct match only).\")\n",
        "         return {\"skill_gaps\": skill_gaps}\n",
        "\n",
        "\n",
        "    individual_skills_set = set([skill.lower() for skill in individual_skills]) # Convert individual skills to lowercase for case-insensitive matching\n",
        "    job_market_skills_set = set([skill.lower() for skill in unique_job_market_skills]) # Convert job market skills to lowercase\n",
        "\n",
        "    skill_gaps = set()\n",
        "\n",
        "    # Helper function to check embedding similarity\n",
        "    def is_covered_by_embedding(job_market_skill_lower, individual_skills_set, job_market_embeddings_dict, individual_embeddings_dict, threshold):\n",
        "        if job_market_skill_lower not in job_market_embeddings_dict:\n",
        "            # print(f\"Job market skill '{job_market_skill_lower}' not in job_market_embeddings_dict.\") # Debug print\n",
        "            return False # Cannot check embedding if no embedding exists\n",
        "\n",
        "        job_market_embedding = job_market_embeddings_dict[job_market_skill_lower].reshape(1, -1)\n",
        "\n",
        "        for individual_skill_lower in individual_skills_set:\n",
        "            if individual_skill_lower in individual_embeddings_dict:\n",
        "                individual_embedding = individual_embeddings_dict[individual_skill_lower].reshape(1, -1)\n",
        "                similarity = cosine_similarity(job_market_embedding, individual_embedding)[0][0]\n",
        "                if similarity >= threshold:\n",
        "                    # print(f\"Embedding match: '{job_market_skill_lower}' and '{individual_skill_lower}' (Similarity: {similarity:.2f})\") # Debug print\n",
        "                    return True\n",
        "            # else:\n",
        "                # print(f\"Individual skill '{individual_skill_lower}' not in individual_embeddings_dict.\") # Debug print\n",
        "        return False\n",
        "\n",
        "\n",
        "    # Identify skill gaps based on direct match or embedding similarity\n",
        "    for job_market_skill in job_market_skills_set:\n",
        "        is_covered = False\n",
        "\n",
        "        # Check for direct match\n",
        "        if job_market_skill in individual_skills_set:\n",
        "            is_covered = True\n",
        "            # print(f\"Direct match: '{job_market_skill}'\") # Debug print\n",
        "            continue # Move to the next job market skill\n",
        "\n",
        "        # Check for coverage by embedding similarity\n",
        "        if is_covered_by_embedding(job_market_skill, individual_skills_set, job_market_embeddings_dict, individual_embeddings_dict, EMBEDDING_SIMILARITY_THRESHOLD):\n",
        "             is_covered = True\n",
        "             # print(f\"Embedding coverage: '{job_market_skill}'\") # Debug print\n",
        "             continue # Move to the next job market skill\n",
        "\n",
        "\n",
        "        # If the skill is not covered by any method, it's a gap\n",
        "        if not is_covered:\n",
        "             skill_gaps.add(job_market_skill)\n",
        "\n",
        "\n",
        "    print(\"\\nIndividual's skills (lowercase):\")\n",
        "    print(individual_skills_set)\n",
        "    print(f\"\\nIdentified {len(skill_gaps)} Specific Skill Gaps (not covered by direct match or embedding similarity).\")\n",
        "\n",
        "\n",
        "    return {\n",
        "        \"skill_gaps\": skill_gaps\n",
        "        # Removing mapping-related output keys\n",
        "        # \"job_market_categories\": set(),\n",
        "        # \"individual_categories\": set(),\n",
        "        # \"category_gaps\": set(),\n",
        "        # \"detailed_skill_gaps\": {}\n",
        "    }\n",
        "\n",
        "\n",
        "# Fallback function identify_skill_gaps_mapping_only is removed as per user request for embeddings only\n",
        "\n",
        "\n",
        "def recommend_learning_paths(skill_gaps_info: dict) -> str:\n",
        "    \"\"\"\n",
        "    Auxiliary Function: Uses an LLM to generate a detailed learning path recommendation\n",
        "    based on the identified skill gaps.\n",
        "    \"\"\"\n",
        "    print(\"---GENERATING LEARNING PATHS (Separate Function)---\")\n",
        "    # Now only using skill_gaps from the input dict\n",
        "    skill_gaps = skill_gaps_info.get('skill_gaps', set())\n",
        "\n",
        "\n",
        "    if not skill_gaps:\n",
        "        print(\"\\nNo skill gaps identified. No recommendations needed.\")\n",
        "        return \"No skill gaps identified.\"\n",
        "\n",
        "    # Configure the LLM\n",
        "    gemini_model = None\n",
        "    recommendations = \"\"\n",
        "    try:\n",
        "        GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "        if GOOGLE_API_KEY:\n",
        "            genai.configure(api_key=GOOGLE_API_KEY)\n",
        "            # Use the working model\n",
        "            gemini_model = genai.GenerativeModel('models/gemini-2.5-flash')\n",
        "            print(\"Google Generative AI model configured for recommendations.\")\n",
        "        else:\n",
        "             print(\"GOOGLE_API_KEY not found in Colab secrets. Cannot configure LLM.\")\n",
        "             return \"Error: LLM not configured.\" # Return error message\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error configuring Google Generative AI model: {e}\")\n",
        "        return f\"Error: LLM configuration failed: {e}\" # Return error message\n",
        "\n",
        "\n",
        "    print(\"\\nGenerating personalized learning path recommendations...\")\n",
        "\n",
        "    # Prepare the prompt for the LLM, focusing on the identified skill gaps\n",
        "    prompt_elements = []\n",
        "\n",
        "    if skill_gaps:\n",
        "         # Add the specific skill gaps identified by embeddings\n",
        "         # Sort skill gaps alphabetically for consistent prompting\n",
        "         sorted_skill_gaps = sorted(list(skill_gaps))\n",
        "         prompt_elements.append(f\"You have identified the following skill gaps: {', '.join(sorted_skill_gaps)}\") # Include all identified gaps\n",
        "\n",
        "\n",
        "    full_prompt_context = \". \".join(prompt_elements)\n",
        "\n",
        "    # Modified prompt for detailed recommendations\n",
        "    prompt = f\"\"\"Based on the following identified skill gaps:\n",
        "\n",
        "{full_prompt_context}\n",
        "\n",
        "Please suggest a detailed learning pathway to acquire these skills. For each key skill or group of related skills, suggest:\n",
        "- Specific learning objectives.\n",
        "- Recommended types of resources (e.g., beginner/intermediate/advanced online courses, books, tutorials, hands-on projects).\n",
        "- A possible sequence or order for learning the skills.\n",
        "- Aim for a comprehensive and actionable plan.\"\"\"\n",
        "\n",
        "\n",
        "    # print(\"\\nPrompt for the LLM:\") # Uncomment to see the full prompt sent to the LLM\n",
        "    # print(prompt) # Uncomment to see the full prompt sent to the LLM\n",
        "\n",
        "\n",
        "    if gemini_model:\n",
        "        try:\n",
        "            response = gemini_model.generate_content(prompt)\n",
        "            recommendations = response.text\n",
        "            # print(\"\\n--- PERSONALIZED LEARNING PATH RECOMMENDATIONS (Simplified) ---\") # Removed internal print\n",
        "            # print(recommendations) # Removed internal print\n",
        "            return recommendations\n",
        "        except Exception as e:\n",
        "            print(f\"Error calling LLM: {e}\")\n",
        "            return f\"Error calling LLM: {e}\" # Return error message\n",
        "    else:\n",
        "         return \"Error: LLM is not configured.\" # Return error message\n",
        "\n",
        "\n",
        "# Define a placeholder node for storing the results\n",
        "def store_results_node(state: GraphState):\n",
        "    \"\"\"\n",
        "    LangGraph Node: Simulates storing the results of the workflow.\n",
        "    This node is included in the compiled graph as a final step.\n",
        "    \"\"\"\n",
        "    print(\"---STORING RESULTS (Placeholder Node)---\")\n",
        "    recommendations = state.get('recommendations')\n",
        "    skill_gaps = state.get('skill_gaps')\n",
        "    # Removing mapping-related attributes from storage summary\n",
        "    # category_gaps = state.get('category_gaps')\n",
        "    # detailed_skill_gaps = state.get('detailed_skill_gaps')\n",
        "\n",
        "\n",
        "    if recommendations or skill_gaps:\n",
        "        print(\"Simulating storing results (e.g., recommendations, skill gaps)...\")\n",
        "        # In a real implementation, you would save these to a database, file, etc.\n",
        "        stored_data_summary = f\"Recommendations: {recommendations[:100]}...\\nSkill Gaps Count: {len(skill_gaps) if skill_gaps else 0}\" # Store a summary\n",
        "        return {\"stored_result\": stored_data_summary, \"error\": \"\"}\n",
        "    else:\n",
        "        print(\"No results to store.\")\n",
        "        return {\"stored_result\": \"No results stored.\", \"error\": \"\"}\n",
        "\n",
        "\n",
        "# --- LangGraph Definition and Compilation (Data Processing Graph) ---\n",
        "# This section defines the structure and flow of the first part of the workflow.\n",
        "\n",
        "# Initialize the graph builder for the data processing workflow\n",
        "workflow_data_processing = StateGraph(GraphState)\n",
        "\n",
        "# Add the nodes to the data processing workflow\n",
        "# These are the functions that will be executed as steps in the graph.\n",
        "workflow_data_processing.add_node(\"load_data\", load_data_node)\n",
        "workflow_data_processing.add_node(\"wrangle_data\", wrangle_data_node)\n",
        "workflow_data_processing.add_node(\"store_results\", store_results_node)\n",
        "\n",
        "\n",
        "# Define transitions (edges) for the data processing graph\n",
        "# These define the order in which nodes are executed.\n",
        "workflow_data_processing.add_edge(\"load_data\", \"wrangle_data\") # After 'load_data', go to 'wrangle_data'\n",
        "workflow_data_processing.add_edge(\"wrangle_data\", \"store_results\") # After 'wrangle_data', go to 'store_results'\n",
        "workflow_data_processing.add_edge(\"store_results\", END) # After 'store_results', end the graph execution\n",
        "\n",
        "\n",
        "# Set the entry point for the data processing graph\n",
        "# This is the node where the graph execution begins.\n",
        "workflow_data_processing.set_entry_point(\"load_data\")\n",
        "\n",
        "# Compile the data processing graph\n",
        "# This prepares the graph for execution.\n",
        "app_data_processing = workflow_data_processing.compile()\n",
        "\n",
        "print(\"\\nFirst LangGraph (Data Processing + Placeholder Storage) compiled.\")\n",
        "print(\"The workflow is: load_data -> wrangle_data -> store_results -> END\")\n",
        "print(\"The functions `identify_skill_gaps` and `recommend_learning_paths` are called separately in the orchestration cell (8a444cd1).\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "First LangGraph (Data Processing + Placeholder Storage) compiled.\n",
            "The workflow is: load_data -> wrangle_data -> store_results -> END\n",
            "The functions `identify_skill_gaps` and `recommend_learning_paths` are called separately in the orchestration cell (8a444cd1).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12e1c718"
      },
      "source": [
        "# Step 1: Install necessary libraries for embeddings\n",
        "%pip install --quiet sentence-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zDAn-XLkifc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0384d119",
        "outputId": "6484a7fe-34b7-49ed-d47c-1bc09a0d9644"
      },
      "source": [
        "# Step 2: Load a pre-trained embedding model\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "print(\"Loading a pre-trained sentence embedding model...\")\n",
        "# Using a general-purpose model like 'all-MiniLM-L6-v2'\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(\"Embedding model loaded successfully.\")\n",
        "\n",
        "# You can test the model with a couple of examples\n",
        "# embeddings = embedding_model.encode([\"Python Programming\", \"Data Analysis\", \"Cooking\"])\n",
        "# print(\"\\nExample embeddings generated.\")\n",
        "# print(embeddings.shape) # Should be (number_of_sentences, embedding_dimension)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading a pre-trained sentence embedding model...\n",
            "Embedding model loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8a444cd1",
        "outputId": "22c277c0-d6cd-4a54-b69d-c965a28e6cc2"
      },
      "source": [
        "# This cell orchestrates the entire workflow:\n",
        "# 1. Invokes the first LangGraph (Data Processing).\n",
        "# 2. Gets user skill input.\n",
        "# 3. Generates embeddings for job market skills.\n",
        "# 4. Generates embeddings for user skills.\n",
        "# 5. Identifies skill gaps using embeddings only for coverage.\n",
        "# 6. Generates and displays personalized learning pathways.\n",
        "\n",
        "print(\"Starting the Skill Gap Analysis and Recommendation Workflow...\") # Keep main starting print\n",
        "\n",
        "# Step 1: Invoke the first LangGraph (Data Processing).\n",
        "# We need to provide the initial state with the dataset path.\n",
        "initial_state_data = {\n",
        "    'dataset_path': './multi-platform-online-courses-dataset/Coursera.csv', # Replace with your actual path\n",
        "    'dataframe': None,\n",
        "    'skills_data': [],\n",
        "    'unique_job_market_skills': set(),\n",
        "    'individual_skills': [],\n",
        "    'skill_gaps': set(),\n",
        "    'recommendations': \"\",\n",
        "    'error': \"\",\n",
        "    # Keep keys in initial state for type consistency, though not used in updated identify_skill_gaps output\n",
        "    'job_market_categories': set(),\n",
        "    'individual_categories': set(),\n",
        "    'category_gaps': set(),\n",
        "    'detailed_skill_gaps': {}\n",
        "}\n",
        "\n",
        "# print(\"Running data processing graph...\") # Suppress intermediate print\n",
        "try:\n",
        "    # Assuming app_data_processing is compiled in a previous cell (f09cee9e)\n",
        "    result_data = app_data_processing.invoke(initial_state_data)\n",
        "    # print(\"Data processing graph finished.\") # Suppress intermediate print\n",
        "\n",
        "    if 'unique_job_market_skills' in result_data and result_data['unique_job_market_skills']:\n",
        "        unique_job_market_skills = result_data['unique_job_market_skills']\n",
        "        # print(f\"Job market skills successfully loaded from the data processing graph ({len(unique_job_market_skills)} unique skills).\") # Suppress intermediate print\n",
        "\n",
        "        # Step 3: Generate embeddings for job market skills\n",
        "        # Assumes embedding_model is loaded in a previous cell (e.g., 0384d119)\n",
        "        if 'embedding_model' in locals() and embedding_model is not None:\n",
        "            print(\"\\n--- Preparing Skill Embeddings ---\") # Keep a brief progress print\n",
        "            # Convert set to list for embedding\n",
        "            job_market_skills_list = list(unique_job_market_skills)\n",
        "            # Generate embeddings in batches if the list is large to save memory/time\n",
        "            # For this size, we can do it directly\n",
        "            job_market_skill_embeddings = embedding_model.encode(job_market_skills_list, show_progress_bar=False) # Suppress progress bar for cleaner output\n",
        "            # print(f\"Generated embeddings for {len(job_market_skills_list)} job market skills.\") # Suppress intermediate print\n",
        "            # Store skills and their embeddings, maybe in a dictionary for easier lookup\n",
        "            job_market_embeddings_dict = dict(zip(job_market_skills_list, job_market_skill_embeddings))\n",
        "            # print(\"Job market embeddings dictionary created.\") # Suppress intermediate print\n",
        "\n",
        "\n",
        "            # Step 2: Ask for user skill input (Order adjusted for clarity)\n",
        "            print(\"\\n--- USER INPUT ---\") # Keep user input prompt\n",
        "            print(\"Please enter your skills, separated by commas:\")\n",
        "            individual_skills_input = input()\n",
        "\n",
        "            # Convert the input string into a list of skills, stripping whitespace\n",
        "            individual_skills = [skill.strip() for skill in individual_skills_input.split(',')]\n",
        "\n",
        "            print(\"\\nYour skills:\") # Keep displaying user skills\n",
        "            print(individual_skills)\n",
        "\n",
        "            # Step 4: Generate embeddings for user skills\n",
        "            individual_embeddings_dict = {} # Initialize in case no skills are entered\n",
        "            if individual_skills:\n",
        "                # print(\"\\n--- GENERATING INDIVIDUAL SKILL EMBEDDINGS ---\") # Suppress intermediate print\n",
        "                individual_skill_embeddings = embedding_model.encode(individual_skills, show_progress_bar=False) # Suppress progress bar for cleaner output\n",
        "                # print(f\"Generated embeddings for {len(individual_skills)} individual skills.\") # Suppress intermediate print\n",
        "                individual_embeddings_dict = dict(zip(individual_skills, individual_skill_embeddings))\n",
        "                # print(\"Individual embeddings dictionary created.\") # Suppress intermediate print\n",
        "            else:\n",
        "                 print(\"No individual skills provided.\") # Keep message if no skills entered\n",
        "\n",
        "\n",
        "            # Step 5: Identify skill gaps using the updated function (now uses embeddings only for coverage)\n",
        "            print(\"\\n--- IDENTIFYING SKILL GAPS ---\") # Keep main step print\n",
        "            # Pass the embedding dictionaries to the identify_skill_gaps function\n",
        "            # The updated function now only returns 'skill_gaps'\n",
        "            # print(f\"Passing unique_job_market_skills ({len(unique_job_market_skills)}), individual_skills ({len(individual_skills)}), job_market_embeddings_dict ({len(job_market_embeddings_dict)}), individual_embeddings_dict ({len(individual_embeddings_dict)}) to identify_skill_gaps.\") # Suppress debug print\n",
        "            skill_gaps_info = identify_skill_gaps(unique_job_market_skills, individual_skills, job_market_embeddings_dict, individual_embeddings_dict)\n",
        "            skill_gaps = skill_gaps_info.get('skill_gaps', set()) # Extract only skill_gaps\n",
        "\n",
        "\n",
        "            # Display the results of the gap analysis (simplified output)\n",
        "            print(f\"\\nIdentified {len(skill_gaps)} Skill Gaps (based on direct match and embedding similarity):\") # Keep simplified gap summary\n",
        "            # Removed display of category gaps and detailed skill gaps\n",
        "\n",
        "\n",
        "            # Step 6: Generate learning path recommendations using LLM\n",
        "            print(\"\\n--- PERSONALIZED LEARNING PATH RECOMMENDATIONS ---\") # Keep main step print\n",
        "\n",
        "            # Pass the simplified skill gap information to the recommendation function\n",
        "            # The recommend_learning_paths function is updated to expect this format\n",
        "            recommendations = recommend_learning_paths({\"skill_gaps\": skill_gaps}) # Pass only the skill_gaps set\n",
        "\n",
        "\n",
        "            if \"Error\" in recommendations:\n",
        "                 print(f\"\\nRecommendation Error: {recommendations}\")\n",
        "            elif recommendations == \"No skill gaps identified.\":\n",
        "                 print(\"\\nNo recommendations needed based on identified gaps.\")\n",
        "            else:\n",
        "                 # print(\"\\n--- PERSONALIZED LEARNING PATH RECOMMENDATIONS ---\") # Suppressed duplicate print\n",
        "                 print(recommendations) # Final output\n",
        "\n",
        "\n",
        "        else:\n",
        "            print(\"\\nError: Embedding model not found. Please run the cell to load the embedding model (e.g., cell 0384d119).\")\n",
        "\n",
        "\n",
        "    else:\n",
        "        print(\"Could not retrieve job market skills from the data processing graph result.\")\n",
        "\n",
        "except NameError:\n",
        "    print(\"\\nError: Required components (e.g., app_data_processing, embedding_model, auxiliary functions) are not defined.\")\n",
        "    print(\"Please ensure you have run the necessary cells to compile the graph, load the embedding model, and define functions.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nAn unexpected error occurred during the workflow: {e}\")\n",
        "\n",
        "print(\"\\nWorkflow Finished.\") # Keep a final message"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting the Skill Gap Analysis and Recommendation Workflow...\n",
            "---LOADING DATA (Graph 1)---\n",
            "Dataset loaded successfully.\n",
            "---WRANGLING DATA (Graph 1)---\n",
            "Total unique cleaned skills extracted: 328\n",
            "---STORING RESULTS (Placeholder Node)---\n",
            "No results to store.\n",
            "\n",
            "--- Preparing Skill Embeddings ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- USER INPUT ---\n",
            "Please enter your skills, separated by commas:\n",
            "html,css,js\n",
            "\n",
            "Your skills:\n",
            "['html', 'css', 'js']\n",
            "\n",
            "--- IDENTIFYING SKILL GAPS ---\n",
            "---IDENTIFYING SKILL GAPS (Using Embeddings Only for Coverage)---\n",
            "\n",
            "Individual's skills (lowercase):\n",
            "{'css', 'html', 'js'}\n",
            "\n",
            "Identified 328 Specific Skill Gaps (not covered by direct match or embedding similarity).\n",
            "\n",
            "Identified 328 Skill Gaps (based on direct match and embedding similarity):\n",
            "\n",
            "--- PERSONALIZED LEARNING PATH RECOMMENDATIONS ---\n",
            "---GENERATING LEARNING PATHS (Separate Function)---\n",
            "Google Generative AI model configured for recommendations.\n",
            "\n",
            "Generating personalized learning path recommendations...\n",
            "This is an exceptionally comprehensive list of skill gaps, spanning almost every major domain in technology, business, and even specialized fields. Acquiring all of these would essentially mean becoming an expert in multiple, distinct careers.\n",
            "\n",
            "Therefore, the first and most crucial step is **prioritization**. This learning pathway will be structured in a modular fashion, allowing you to focus on specific career trajectories. It's impossible to learn all of these simultaneously or even sequentially within a reasonable timeframe.\n",
            "\n",
            "**Recommendation:** Before embarking on this, identify **1-3 career paths or roles** that interest you most, and then focus on the corresponding skill clusters.\n",
            "\n",
            "---\n",
            "\n",
            "## Detailed Learning Pathway for Identified Skill Gaps\n",
            "\n",
            "This pathway is organized into major skill clusters, acknowledging that many skills are interdependent.\n",
            "\n",
            "### **Phase 0: Foundational Skills (Core to Any Professional Role)**\n",
            "\n",
            "These skills are broadly applicable and should be developed continuously.\n",
            "\n",
            "**1. Critical Thinking & Problem Solving**\n",
            "    *   **Learning Objectives:**\n",
            "        *   Analyze information objectively and identify logical fallacies.\n",
            "        *   Formulate clear problems and break them down into manageable components.\n",
            "        *   Generate and evaluate multiple solutions, selecting the most appropriate.\n",
            "        *   Apply structured problem-solving methodologies (e.g., root cause analysis, SWOT).\n",
            "    *   **Recommended Resources:**\n",
            "        *   Books: \"Thinking, Fast and Slow\" by Daniel Kahneman, \"Influence\" by Robert Cialdini.\n",
            "        *   Online Courses: Coursera/edX courses on Critical Thinking, Decision Making, or Behavioral Economics.\n",
            "        *   Practice: Solve brain teasers, analyze news articles for bias, participate in case study competitions.\n",
            "    *   **Sequence:** Ongoing, integrated into all other learning.\n",
            "\n",
            "**2. Communication & Collaboration**\n",
            "    *   **Learning Objectives:**\n",
            "        *   Convey complex information clearly and concisely (written and verbal).\n",
            "        *   Practice active listening and provide constructive feedback.\n",
            "        *   Negotiate effectively and manage conflict constructively.\n",
            "        *   Collaborate effectively in diverse teams, both in-person and remotely.\n",
            "        *   Develop storytelling abilities for presentations and reports.\n",
            "    *   **Recommended Resources:**\n",
            "        *   Books: \"Crucial Conversations,\" \"Nonviolent Communication,\" \"Storytelling with Data.\"\n",
            "        *   Online Courses: Public speaking workshops, business communication courses (e.g., from Wharton, Stanford).\n",
            "        *   Practice: Join Toastmasters, volunteer for team projects, practice presentations.\n",
            "    *   **Sequence:** Ongoing, integrated into all other learning.\n",
            "\n",
            "**3. Adaptability & Resilience**\n",
            "    *   **Learning Objectives:**\n",
            "        *   Embrace change and uncertainty positively.\n",
            "        *   Recover quickly from setbacks and learn from failures.\n",
            "        *   Develop a growth mindset and continuously seek new knowledge.\n",
            "        *   Manage stress and maintain well-being under pressure.\n",
            "    *   **Recommended Resources:**\n",
            "        *   Books: \"Mindset\" by Carol Dweck, \"Grit\" by Angela Duckworth.\n",
            "        *   Online Courses: Courses on emotional intelligence, stress management, positive psychology.\n",
            "        *   Practice: Reflect on challenges, seek out new experiences, engage in mindfulness exercises.\n",
            "    *   **Sequence:** Ongoing, integrated into all other learning.\n",
            "\n",
            "---\n",
            "\n",
            "### **Phase 1: Core Computing & Programming Fundamentals**\n",
            "\n",
            "This phase is essential for almost any tech-related role (Software Development, Data Science, Cloud, Cybersecurity, etc.).\n",
            "\n",
            "**4. Computer Science & Programming Principles**\n",
            "    *   **Learning Objectives:**\n",
            "        *   Understand fundamental programming concepts (variables, loops, functions, OOP).\n",
            "        *   Learn data structures (arrays, linked lists, trees, graphs) and algorithms (sorting, searching).\n",
            "        *   Grasp computational thinking and problem decomposition.\n",
            "        *   Understand basic computer architecture and operating systems.\n",
            "        *   Write clean, efficient, and well-documented code.\n",
            "    *   **Recommended Resources:**\n",
            "        *   Beginner Course: Harvard's CS50 (Introduction to Computer Science)  excellent for foundational knowledge across multiple languages.\n",
            "        *   Books: \"Grokking Algorithms,\" \"Clean Code.\"\n",
            "        *   Online Platforms: LeetCode (for algorithms practice), HackerRank.\n",
            "    *   **Sequence:**\n",
            "        1.  CS50 / Introduction to Programming (Python recommended for beginners).\n",
            "        2.  Data Structures and Algorithms (intermediate).\n",
            "        3.  Operating Systems / Computer Architecture basics.\n",
            "\n",
            "**5. Core Programming Languages (Python & SQL)**\n",
            "    *   **Learning Objectives:**\n",
            "        *   **Python:** Write scripts, build basic applications, work with data libraries (Numpy, Pandas).\n",
            "        *   **SQL:** Design relational databases, query data efficiently (SELECT, INSERT, UPDATE, DELETE), understand joins, aggregate functions.\n",
            "    *   **Recommended Resources:**\n",
            "        *   **Python:** Codecademy, Udemy courses (e.g., \"Automate the Boring Stuff with Python\"), \"Python Crash Course\" book.\n",
            "        *   **SQL:** SQLZoo, Mode Analytics SQL Tutorial, \"SQL in 10 Minutes a Day\" book, PostgreSQL/MySQL documentation.\n",
            "    *   **Sequence:** Can be learned concurrently or sequentially after foundational programming. Python is versatile for Data Science, Web Dev, and Automation. SQL is fundamental for data management.\n",
            "\n",
            "---\n",
            "\n",
            "### **Phase 2: Data Science & Machine Learning**\n",
            "\n",
            "This cluster is for roles like Data Analyst, Data Scientist, ML Engineer, Business Intelligence Analyst.\n",
            "\n",
            "**6. Mathematics for Data Science**\n",
            "    *   **Learning Objectives:**\n",
            "        *   **Algebra:** Linear equations, matrices, vectors (foundational for ML).\n",
            "        *   **Calculus:** Derivatives, integrals (optimization in ML).\n",
            "        *   **Probability & Statistics:** Descriptive statistics, probability distributions, hypothesis testing, regression analysis, Bayesian statistics.\n",
            "    *   **Recommended Resources:**\n",
            "        *   Online Courses: Khan Academy (Algebra, Calculus, Statistics), edX/Coursera (e.g., \"Mathematics for Machine Learning\" by Imperial College London).\n",
            "        *   Books: \"No Starch Press\" series for accessible math, \"Think Stats.\"\n",
            "    *   **Sequence:** Basic Algebra/Stats first, then Linear Algebra/Calculus as needed for deeper ML concepts.\n",
            "\n",
            "**7. Data Analysis & Visualization**\n",
            "    *   **Learning Objectives:**\n",
            "        *   Perform exploratory data analysis (EDA).\n",
            "        *   Clean and preprocess raw data.\n",
            "        *   Use tools like Excel, Power BI, Tableau for data manipulation and visualization.\n",
            "        *   Create compelling visual narratives from data.\n",
            "        *   Understand different chart types and when to use them.\n",
            "    *   **Recommended Resources:**\n",
            "        *   **Excel:** Microsoft Excel courses (beginner to advanced), \"Excel Bible\" book.\n",
            "        *   **Power BI/Tableau:** Official documentation, specific Udemy/Coursera courses, \"Storytelling with Data\" book.\n",
            "        *   **Python Libraries:** Matplotlib, Seaborn, Plotly (for interactive visualization).\n",
            "    *   **Sequence:** Excel (basic) -> Python/SQL (intermediate) -> Tableau/Power BI -> Advanced Python visualization.\n",
            "\n",
            "**8. Core Machine Learning & Deep Learning**\n",
            "    *   **Learning Objectives:**\n",
            "        *   Understand different ML paradigms (supervised, unsupervised, reinforcement learning).\n",
            "        *   Implement common ML algorithms (regression, classification, clustering).\n",
            "        *   Understand artificial neural networks, deep learning architectures (CNNs, RNNs), and NLP basics.\n",
            "        *   Evaluate model performance and mitigate bias.\n",
            "        *   Familiarity with frameworks like TensorFlow, PyTorch.\n",
            "    *   **Recommended Resources:**\n",
            "        *   Beginner: Andrew Ng's Machine Learning course (Coursera), \"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow\" book.\n",
            "        *   Deep Learning: DeepLearning.AI Specialization (Coursera).\n",
            "        *   NLP: \"Speech and Language Processing\" by Jurafsky & Martin (online), specialized NLP courses.\n",
            "        *   Computer Vision: OpenCV tutorials, specific courses on CNNs.\n",
            "    *   **Sequence:** ML basics -> Deep Learning basics -> Specialized areas (NLP, CV) -> Applied Machine Learning.\n",
            "\n",
            "**9. Big Data & Data Engineering**\n",
            "    *   **Learning Objectives:**\n",
            "        *   Understand distributed computing architecture.\n",
            "        *   Work with big data concepts (Hadoop, Spark).\n",
            "        *   Design and implement data pipelines (ETL).\n",
            "        *   Understand data warehousing and data lakes.\n",
            "        *   Familiarity with NoSQL databases.\n",
            "    *   **Recommended Resources:**\n",
            "        *   Online Courses: \"Data Engineering with Google Cloud Platform\" (Coursera), specific courses on Apache Spark, Hadoop.\n",
            "        *   Books: \"Designing Data-Intensive Applications.\"\n",
            "        *   Tools: Apache Kafka, MongoDB, Cassandra tutorials.\n",
            "    *   **Sequence:** After core ML/data analysis, or in parallel if aiming for Data Engineer role.\n",
            "\n",
            "---\n",
            "\n",
            "### **Phase 3: Cloud & DevOps**\n",
            "\n",
            "Critical for Cloud Engineers, DevOps Engineers, and modern software development.\n",
            "\n",
            "**10. Cloud Computing Fundamentals**\n",
            "    *   **Learning Objectives:**\n",
            "        *   Understand cloud service models (IaaS, PaaS, SaaS) and deployment models.\n",
            "        *   Familiarity with core services of major cloud providers (AWS, GCP, Azure).\n",
            "        *   Concepts of scalability, elasticity, availability, and cost optimization.\n",
            "        *   Cloud API, Cloud Storage, Cloud Networking basics.\n",
            "    *   **Recommended Resources:**\n",
            "        *   Beginner Certifications: AWS Certified Cloud Practitioner, Google Cloud Digital Leader, Azure Fundamentals (AZ-900).\n",
            "        *   Online Courses: Official cloud provider training portals (AWS Skill Builder, Google Cloud Skills Boost, Microsoft Learn).\n",
            "    *   **Sequence:** Start with one cloud provider's fundamental certification.\n",
            "\n",
            "**11. DevOps & Infrastructure as Code**\n",
            "    *   **Learning Objectives:**\n",
            "        *   Understand DevOps principles (CI/CD, automation, monitoring).\n",
            "        *   Familiarity with version control (Git).\n",
            "        *   Containerization (Docker) and Orchestration (Kubernetes).\n",
            "        *   Infrastructure as Code (Terraform, CloudFormation).\n",
            "        *   Continuous integration and continuous delivery pipelines.\n",
            "    *   **Recommended Resources:**\n",
            "        *   Online Courses: \"DevOps Fundamentals\" (various platforms), specific courses on Docker, Kubernetes.\n",
            "        *   Books: \"The Phoenix Project,\" \"The DevOps Handbook.\"\n",
            "        *   Tools: Jenkins, GitLab CI/CD, Ansible, Chef.\n",
            "    *   **Sequence:** After Cloud Fundamentals.\n",
            "\n",
            "---\n",
            "\n",
            "### **Phase 4: Web & Mobile Development**\n",
            "\n",
            "For Front-end, Back-end, Full-stack, Android/iOS Developers.\n",
            "\n",
            "**12. Front-End Web Development**\n",
            "    *   **Learning Objectives:**\n",
            "        *   Master HTML for structuring content.\n",
            "        *   Master CSS for styling and responsiveness.\n",
            "        *   Master JavaScript for interactivity and dynamic content.\n",
            "        *   Understand modern frameworks (e.g., React, Angular, Vue.js).\n",
            "        *   Principles of user experience (UX) and user interface (UI) design.\n",
            "    *   **Recommended Resources:**\n",
            "        *   HTML/CSS/JS: FreeCodeCamp, MDN Web Docs, \"Eloquent JavaScript\" book.\n",
            "        *   Frameworks: Official documentation (React, Angular), specific Udemy/Coursera courses.\n",
            "        *   Design: \"Don't Make Me Think\" by Steve Krug, Figma/Adobe XD tutorials.\n",
            "    *   **Sequence:** HTML -> CSS -> JavaScript -> Front-end Framework -> UX/UI basics.\n",
            "\n",
            "**13. Back-End Web Development**\n",
            "    *   **Learning Objectives:**\n",
            "        *   Choose and use a back-end programming language (Python/Flask/Django, Node.js/Express, Java/Spring, Ruby on Rails).\n",
            "        *   Design and implement RESTful APIs.\n",
            "        *   Interact with databases (SQL and NoSQL).\n",
            "        *   Implement authentication and authorization.\n",
            "        *   Understand server deployment and scaling.\n",
            "    *   **Recommended Resources:**\n",
            "        *   Language/Framework Specific: Official documentation, \"The Odin Project\" (full-stack focus), specific courses.\n",
            "        *   Books: \"Designing APIs with Swagger and OpenAPI.\"\n",
            "        *   Databases: PostgreSQL tutorials, MongoDB tutorials.\n",
            "    *   **Sequence:** After core programming & SQL. Choose one language/framework ecosystem.\n",
            "\n",
            "**14. Mobile Development (iOS & Android)**\n",
            "    *   **Learning Objectives:**\n",
            "        *   **iOS:** Learn Swift, Xcode, and Apple's development guidelines.\n",
            "        *   **Android:** Learn Java/Kotlin, Android Studio, and Google's development guidelines.\n",
            "        *   Understand mobile UI/UX principles.\n",
            "        *   Build and deploy mobile applications.\n",
            "        *   Cross-platform development (e.g., React Native, Flutter) if desired.\n",
            "    *   **Recommended Resources:**\n",
            "        *   **iOS:** Apple's developer documentation, Hacking with Swift.\n",
            "        *   **Android:** Google's official Android developer tutorials, specific Udemy/Coursera courses.\n",
            "        *   Cross-platform: React Native/Flutter official docs, tutorials.\n",
            "    *   **Sequence:** After core programming. Choose one platform (iOS or Android) or explore cross-platform.\n",
            "\n",
            "---\n",
            "\n",
            "### **Phase 5: Business & Management**\n",
            "\n",
            "For roles like Project Manager, Product Manager, Business Analyst, Strategy Consultant, Entrepreneur.\n",
            "\n",
            "**15. Project & Product Management**\n",
            "    *   **Learning Objectives:**\n",
            "        *   **Project Management:** Plan, execute, and close projects; manage scope, budget, and resources; understand Agile and Waterfall methodologies.\n",
            "        *   **Product Management:** Identify market needs, define product vision/strategy, manage product lifecycle, conduct user research, create product roadmaps.\n",
            "    *   **Recommended Resources:**\n",
            "        *   Project: PMI's PMBOK Guide, Scrum.org (for Scrum Master/Product Owner certs), Coursera Project Management Specialization (Google/IBM).\n",
            "        *   Product: \"Inspired\" by Marty Cagan, \"Cracking the PM Interview,\" \"Product Management Fundamentals\" courses.\n",
            "        *   Tools: Jira, Asana, Trello.\n",
            "    *   **Sequence:** Project Management (general) -> Agile (specific) -> Product Management (strategic/user-focused).\n",
            "\n",
            "**16. Business Analysis & Strategy**\n",
            "    *   **Learning Objectives:**\n",
            "        *   Gather and analyze business requirements.\n",
            "        *   Model business processes.\n",
            "        *   Conduct market analysis and competitive intelligence.\n",
            "        *   Develop business strategies and transformation plans.\n",
            "        *   Understand business intelligence and data-driven decision-making.\n",
            "    *   **Recommended Resources:**\n",
            "        *   Books: \"Business Model Generation,\" \"Lean Startup.\"\n",
            "        *   Online Courses: IIBA (International Institute of Business Analysis) certifications, Business Strategy courses from top universities.\n",
            "        *   Practice: Case studies, analyze company financial reports.\n",
            "    *   **Sequence:** Business fundamentals -> Market Research -> Business Analysis -> Strategy.\n",
            "\n",
            "**17. Leadership & People Management**\n",
            "    *   **Learning Objectives:**\n",
            "        *   Develop effective leadership styles and motivate teams.\n",
            "        *   Perform performance management and provide constructive feedback.\n",
            "        *   Understand organizational development and change management.\n",
            "        *   Foster a positive team culture and manage conflict.\n",
            "        *   Develop emotional intelligence.\n",
            "    *   **Recommended Resources:**\n",
            "        *   Books: \"Leaders Eat Last,\" \"Dare to Lead,\" \"Drive.\"\n",
            "        *   Online Courses: Leadership Development programs (e.g., from Wharton, Michigan), HR management courses.\n",
            "        *   Practice: Take on leadership roles in projects, mentor others.\n",
            "    *   **Sequence:** Ongoing, but formal learning can begin after foundational skills.\n",
            "\n",
            "---\n",
            "\n",
            "### **Phase 6: Specialized Business Functions**\n",
            "\n",
            "For specific roles in Marketing, Sales, Finance, Accounting, and HR.\n",
            "\n",
            "**18. Sales & Marketing**\n",
            "    *   **Learning Objectives:**\n",
            "        *   **Marketing:** Understand market research, branding, digital marketing (SEO, SEM, social media), content marketing, product marketing.\n",
            "        *   **Sales:** Master prospecting, qualification, negotiation, closing techniques, customer relationship management (CRM).\n",
            "        *   Advertising: Strategies for different platforms, ad sales.\n",
            "    *   **Recommended Resources:**\n",
            "        *   Marketing: HubSpot Academy (free certifications), Google Analytics Academy, \"Influence\" by Robert Cialdini, \"Permission Marketing\" by Seth Godin.\n",
            "        *   Sales: \"Spin Selling,\" Salesforce Trailhead, Sandler Training concepts.\n",
            "        *   Tools: Salesforce, HubSpot.\n",
            "    *   **Sequence:** Marketing Fundamentals -> Digital Marketing -> Specific Sales techniques.\n",
            "\n",
            "**19. Finance & Accounting**\n",
            "    *   **Learning Objectives:**\n",
            "        *   **Accounting:** Understand financial accounting, corporate accounting, management accounting, cost accounting, accounts payable/receivable, taxes, audit.\n",
            "        *   **Finance:** Financial analysis, investment management, cash management, risk management, fintech concepts.\n",
            "        *   Budget management, billing & invoicing.\n",
            "    *   **Recommended Resources:**\n",
            "        *   Accounting: \"Financial Accounting For Dummies,\" ACCA/CPA preparatory courses (for professional certs), accounting software tutorials (QuickBooks, SAP).\n",
            "        *   Finance: Coursera \"Introduction to Finance\" (Wharton), CFA (Chartered Financial Analyst) materials (advanced), \"The Intelligent Investor.\"\n",
            "    *   **Sequence:** Financial Accounting -> Management Accounting -> Financial Analysis -> Specialized areas.\n",
            "\n",
            "**20. Human Resources**\n",
            "    *   **Learning Objectives:**\n",
            "        *   Understand recruitment, talent management, compensation & benefits, employee relations.\n",
            "        *   Familiarity with HR tech and people analysis.\n",
            "        *   Develop training and development programs.\n",
            "    *   **Recommended Resources:**\n",
            "        *   SHRM (Society for Human Resource Management) resources/certifications.\n",
            "        *   Online Courses: HR Management specializations.\n",
            "        *   Books: \"Work Rules!\" by Laszlo Bock.\n",
            "    *   **Sequence:** HR Fundamentals -> Specific HR functions (Recruitment, Comp & Ben).\n",
            "\n",
            "---\n",
            "\n",
            "### **Phase 7: Cybersecurity**\n",
            "\n",
            "For Security Analysts, Engineers, or Architects.\n",
            "\n",
            "**21. Cybersecurity**\n",
            "    *   **Learning Objectives:**\n",
            "        *   Understand common cyberattacks and security models.\n",
            "        *   Network security, system security, software security.\n",
            "        *   Security engineering and security strategy.\n",
            "        *   Computer security incident management.\n",
            "        *   Cryptography basics.\n",
            "    *   **Recommended Resources:**\n",
            "        *   Certifications: CompTIA Security+, CySA+, CEH (Certified Ethical Hacker).\n",
            "        *   Online Courses: SANS Institute (advanced), specific courses on network security, penetration testing.\n",
            "        *   Books: \"The Art of Invisibility\" by Kevin Mitnick.\n",
            "    *   **Sequence:** Networking fundamentals -> Operating Systems -> Security Fundamentals -> Specialized areas.\n",
            "\n",
            "---\n",
            "\n",
            "### **Phase 8: Design & Niche Technologies**\n",
            "\n",
            "For UX/UI Designers, Graphic Designers, or specialists in emerging tech.\n",
            "\n",
            "**22. Design (Graphic, UX, UI)**\n",
            "    *   **Learning Objectives:**\n",
            "        *   **Graphic Design:** Principles of visual design, use graphics software (Adobe Creative Suite).\n",
            "        *   **User Experience (UX):** User research, persona creation, information architecture, wireframing, usability testing.\n",
            "        *   **User Interface (UI):** Layout, typography, color theory, interactive design, UI toolkits.\n",
            "    *   **Recommended Resources:**\n",
            "        *   Graphic: Adobe tutorials, \"Designing with Type\" book.\n",
            "        *   UX/UI: Nielsen Norman Group articles, \"The Design of Everyday Things\" by Don Norman, Google UX Design Professional Certificate.\n",
            "        *   Tools: Figma, Sketch, Adobe XD, Photoshop, Illustrator.\n",
            "    *   **Sequence:** Graphic Design (visual principles) -> UX Research -> UI Design.\n",
            "\n",
            "**23. Geographic Information Systems (GIS)**\n",
            "    *   **Learning Objectives:**\n",
            "        *   Understand spatial data analysis and geovisualization.\n",
            "        *   Use ArcGIS and other GIS software.\n",
            "        *   Concepts of remote sensing and cartography.\n",
            "    *   **Recommended Resources:**\n",
            "        *   ESRI (ArcGIS) official training, specific university courses on GIS.\n",
            "        *   Books: \"GIS Fundamentals.\"\n",
            "    *   **Sequence:** Can be learned independently if relevant to a specific career path.\n",
            "\n",
            "**24. Emerging Technologies (IoT, Blockchain, VR)**\n",
            "    *   **Learning Objectives:**\n",
            "        *   **IoT:** Understand embedded systems, sensor networks, cloud connectivity for IoT.\n",
            "        *   **Blockchain:** Understand distributed ledgers, cryptocurrencies, smart contracts.\n",
            "        *   **Virtual Reality:** Principles of VR design and development.\n",
            "    *   **Recommended Resources:**\n",
            "        *   Online Courses: Specific courses on each technology (e.g., \"Blockchain Basics\" on Coursera).\n",
            "        *   Hardware kits for IoT.\n",
            "        *   Unity/Unreal Engine tutorials for VR.\n",
            "    *   **Sequence:** Learn fundamentals of each based on interest, often requiring strong programming or networking foundations.\n",
            "\n",
            "---\n",
            "\n",
            "### **Phase 9: Continuous Learning & Professional Development**\n",
            "\n",
            "This is an ongoing commitment throughout your career.\n",
            "\n",
            "**25. Professional Development & Learning Strategies**\n",
            "    *   **Learning Objectives:**\n",
            "        *   Identify personal learning styles and optimize study habits.\n",
            "        *   Manage time effectively and prioritize tasks.\n",
            "        *   Develop a network of peers and mentors.\n",
            "        *   Stay updated with industry trends and emerging technologies.\n",
            "        *   Curate a professional portfolio showcasing skills and projects.\n",
            "    *   **Recommended Resources:**\n",
            "        *   Books: \"Ultralearning\" by Scott H. Young, \"Atomic Habits\" by James Clear.\n",
            "        *   Platforms: LinkedIn Learning, Coursera, edX, Udemy, Pluralsight for continuous skill upgrades.\n",
            "        *   Conferences, webinars, industry blogs.\n",
            "    *   **Sequence:** Ongoing, integrated into all phases.\n",
            "\n",
            "---\n",
            "\n",
            "### **General Recommendations for this Immense Pathway:**\n",
            "\n",
            "1.  **Prioritize Ruthlessly:** As mentioned, trying to learn all of this is unrealistic. Choose a career path (e.g., \"Data Scientist,\" \"Full-Stack Developer,\" \"Product Manager with Technical Acumen\") and focus *only* on the relevant clusters.\n",
            "2.  **Start with Fundamentals:** Do not skip the foundational CS, programming, math, and soft skills. They are the building blocks.\n",
            "3.  **Hands-On Projects:** Theory is not enough. For every technical skill, work on personal projects, contribute to open source, or participate in hackathons. Build a portfolio.\n",
            "4.  **Certifications (Strategic):** For Cloud, Project Management, and Cybersecurity, industry certifications can validate your skills and boost your resume.\n",
            "5.  **Community & Networking:** Join online communities, attend meetups (virtual or in-person), and connect with professionals in your target fields.\n",
            "6.  **Patience & Consistency:** Learning takes time. Break down objectives into small, manageable chunks and maintain a consistent learning schedule.\n",
            "7.  **Iterate and Specialize:** As you learn, you'll discover what you enjoy and excel at. This will help you further refine your specialization.\n",
            "\n",
            "Good luck on your learning journey!\n",
            "\n",
            "Workflow Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vpUaTyKPuVi4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}